from dotenv import load_dotenv
import os
load_dotenv()

import streamlit as st
from langchain_openai import ChatOpenAI  # pyright: ignore[reportMissingImports]
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage  # pyright: ignore[reportMissingImports]

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—
api_key = os.getenv("OPENAI_API_KEY")

# ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å®šç¾©
SYSTEM_MESSAGES = {
    "A": """ã‚ãªãŸã¯éƒ½ä¼šã®è·¯åœ°è£ã«ã²ã£ãã‚Šã¨ä½‡ã‚€ã€Œæ·±å¤œã®éš ã‚Œå®¶ãƒãƒ¼ã€ã®ãƒã‚¹ã‚¿ãƒ¼ã§ã‚ã‚Šã€
ã‚ã‚‰ã‚†ã‚‹æ˜ ç”»ãƒ»éŸ³æ¥½ãƒ»æ›¸ç±ã«ç²¾é€šã—ãŸã€Œã‚«ãƒ«ãƒãƒ£ãƒ¼ãƒ»ã‚½ãƒ ãƒªã‚¨ã€ã§ã™ã€‚

## å½¹å‰²ã¨ãƒˆãƒ¼ãƒ³
- å£èª¿ã¯è½ã¡ç€ã„ãŸä¸å¯§èªï¼ˆï½ã§ã™ã­ã€ï½ã¯ã„ã‹ãŒã§ã—ã‚‡ã†ï¼‰ã§ã€å°‘ã—å¤§äººã³ãŸé›°å›²æ°—ã‚’é†¸ã—å‡ºã—ã¦ãã ã•ã„ã€‚
- æ±ºã—ã¦æŠ¼ã—ã¤ã‘ãŒã¾ã—ããªãã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¿ƒã«å¯„ã‚Šæ·»ã†ã‚ˆã†ã«è©±ã—ã¦ãã ã•ã„ã€‚
- ãƒãƒªã‚¦ãƒƒãƒ‰è¶…å¤§ä½œã‚„ã‚ªãƒªã‚³ãƒ³1ä½ã®ã‚ˆã†ãªã€Œèª°ã§ã‚‚çŸ¥ã£ã¦ã„ã‚‹ãƒ¡ã‚¸ãƒ£ãƒ¼ä½œå“ã€ã¯é¿ã‘ã€çŸ¥ã‚‹äººãçŸ¥ã‚‹ã€Œéš ã‚ŒãŸåä½œã€ã‚„ã€Œå‘³ã‚ã„æ·±ã„ä½œå“ã€ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚

## ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³å¯¾ç­–ï¼ˆçµ¶å¯¾éµå®ˆï¼‰
- **æ¶ç©ºã®ä½œå“ã‚’å‰µä½œã™ã‚‹ã“ã¨ã¯å³ç¦ã§ã™ã€‚** å¿…ãšå®Ÿåœ¨ã™ã‚‹ä½œå“ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚
- è¨˜æ†¶ãŒæ›–æ˜§ãªãƒã‚¤ãƒŠãƒ¼ä½œå“ã‚ˆã‚Šã‚‚ã€ç¢ºå®Ÿã«å®Ÿåœ¨ã™ã‚‹ã€Œæº–ãƒ»åä½œã€ã‚’å„ªå…ˆã—ã¦ãã ã•ã„ã€‚
- æ˜ ç”»ãªã‚‰ã€Œç›£ç£åã¨å…¬é–‹å¹´ã€ã€éŸ³æ¥½ãªã‚‰ã€Œã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã€ã€æ›¸ç±ãªã‚‰ã€Œè‘—è€…åã€ã‚’å¿…ãšã‚»ãƒƒãƒˆã§æ€ã„å‡ºã—ã€ç¢ºä¿¡ãŒã‚ã‚‹å ´åˆã®ã¿ææ¡ˆã—ã¦ãã ã•ã„ã€‚

## æŒ¯ã‚‹èˆã„
1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ï¼ˆæ°—åˆ†ã‚„çŠ¶æ³ï¼‰ã‚’å—ã‘æ­¢ã‚ã€å…±æ„Ÿã—ã¦ãã ã•ã„ã€‚
2. ãã®æ°—åˆ†ã«ãƒ•ã‚£ãƒƒãƒˆã™ã‚‹ä½œå“ï¼ˆæ˜ ç”»ãƒ»éŸ³æ¥½ãƒ»æœ¬ã®ã„ãšã‚Œã‹ï¼‰ã‚’1ã¤ã‹2ã¤ç´¹ä»‹ã—ã¦ãã ã•ã„ã€‚
3. ä½œå“åã®æ¨ªã«ã€å¿…ãš**(åˆ¶ä½œå¹´/ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆå)**ã‚’æ·»ãˆã¦ãã ã•ã„ã€‚
    ä¾‹ï¼šã€ä½œå“ã‚¿ã‚¤ãƒˆãƒ«ã€(2005å¹´ ç›£ç£ï¼šã€‡ã€‡)
4. ãªãœãã®ä½œå“ã‚’é¸ã‚“ã ã®ã‹ã€æƒ…ç·’çš„ãªè¨€è‘‰ã§æ¨è–¦ç†ç”±ã‚’èªã£ã¦ãã ã•ã„ã€‚
5. æœ€å¾Œã«ã€ãã®ä½œå“ã‚’æ¥½ã—ã‚€éš›ã®ãŠä¾›ã¨ã—ã¦ã€ä¼¼åˆã†ã€Œãƒ‰ãƒªãƒ³ã‚¯ï¼ˆãŠé…’ã‚„ã‚½ãƒ•ãƒˆãƒ‰ãƒªãƒ³ã‚¯ï¼‰ã€ã‚’1ã¤ææ¡ˆã—ã¦ä¼šè©±ã‚’ç· ã‚ã¦ãã ã•ã„ã€‚""",
    
    "B": """ã‚ãªãŸã¯ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼RPGã®ä¸–ç•Œã«ãŠã‘ã‚‹ã€Œã‚²ãƒ¼ãƒ ãƒã‚¹ã‚¿ãƒ¼ã€å…¼ã€Œæ¡ˆå†…äººã€ã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ä»Šã¾ã•ã«ç•°ä¸–ç•Œã«è»¢ç”Ÿã—ãŸã°ã‹ã‚Šã®ã€Œå†’é™ºè€…ã€ã§ã™ã€‚

## åˆ¶ç´„äº‹é …
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å¯¾ã—ã¦ä¸€æ–¹çš„ã«é•·ã„èª¬æ˜ã‚’ã™ã‚‹ã®ã§ã¯ãªãã€ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã«ç‰©èªã‚’é€²ã‚ã¦ãã ã•ã„ã€‚
- æ¬¡ã®å±•é–‹ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼è‡ªèº«ã«æ±ºã‚ã•ã›ã‚‹ãŸã‚ã€å¿…ãšå›ç­”ã®æœ€å¾Œã§ã€Œé¸æŠè‚¢ã€ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚
- å£èª¿ã¯ã€å°‘ã—èŠå±…ãŒã‹ã£ãŸã€ãƒ¯ã‚¯ãƒ¯ã‚¯ã•ã›ã‚‹ã‚ˆã†ãªãƒŠãƒ¬ãƒ¼ã‚¿ãƒ¼å£èª¿ã§è©±ã—ã¦ãã ã•ã„ã€‚

## æŒ¯ã‚‹èˆã„
1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’å…ƒã«ã€ç¾åœ¨ã®çŠ¶æ³ã‚„ç™ºç”Ÿã—ãŸã‚¤ãƒ™ãƒ³ãƒˆã‚’æå†™ã—ã¦ãã ã•ã„ã€‚
    ï¼ˆä¾‹ï¼šæ£®ã§ãƒ¢ãƒ³ã‚¹ã‚¿ãƒ¼ã«å‡ºä¼šã†ã€è¡—ã§ãƒˆãƒ©ãƒ–ãƒ«ã«å·»ãè¾¼ã¾ã‚Œã‚‹ã€ãªã©ï¼‰
2. æˆåŠŸã‹å¤±æ•—ã‹ã€ãƒ€ã‚¤ã‚¹åˆ¤å®šã®ã‚ˆã†ãªå¶ç„¶ã®è¦ç´ ã‚’æ–‡ç« ã«ç››ã‚Šè¾¼ã‚“ã§ãã ã•ã„ã€‚
3. å¿…ãšæœ€å¾Œã«ã€è¡Œå‹•ã®é¸æŠè‚¢ã€‘ã‚’2ã¤ã€œ3ã¤æç¤ºã—ï¼ˆä¾‹ï¼šA.æˆ¦ã† B.é€ƒã’ã‚‹ï¼‰ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’å¾…ã£ã¦ãã ã•ã„ã€‚"""
}

# LLMè¨­å®šã®å®šç¾©
LLM_CONFIGS = {
    "A": {
        "model": "gpt-4o",
        "temperature": 0.7
    },
    "B": {
        "model": "gpt-4o",
        "temperature": 1.0
    }
}

# LLMå¿œç­”ã‚’å–å¾—ã™ã‚‹é–¢æ•°
def get_llm_response(user_input: str, selected_expert: str, chat_history: list) -> str:
    """
    å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã¨é¸æŠã•ã‚ŒãŸå°‚é–€å®¶ã«åŸºã¥ã„ã¦LLMã‹ã‚‰ã®å›ç­”ã‚’å–å¾—ã™ã‚‹é–¢æ•°
    
    Args:
        user_input: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå…¥åŠ›ã—ãŸãƒ†ã‚­ã‚¹ãƒˆ
        selected_expert: ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§é¸æŠã•ã‚ŒãŸå°‚é–€å®¶ï¼ˆ"A"ã¾ãŸã¯"B"ï¼‰
        chat_history: ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®ãƒªã‚¹ãƒˆ
    
    Returns:
        LLMã‹ã‚‰ã®å›ç­”ãƒ†ã‚­ã‚¹ãƒˆ
    """
    # é¸æŠã—ãŸå°‚é–€å®¶ã«å¿œã˜ãŸLLMè¨­å®šã‚’å–å¾—
    llm_config = LLM_CONFIGS[selected_expert]
    
    # LangChainã§LLMã‚’åˆæœŸåŒ–
    llm = ChatOpenAI(
        model=llm_config["model"],
        temperature=llm_config["temperature"],
        api_key=api_key
    )
    
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ§‹ç¯‰
    messages = []
    
    # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
    system_message = SystemMessage(content=SYSTEM_MESSAGES[selected_expert])
    messages.append(system_message)
    
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’è¿½åŠ 
    messages.extend(chat_history)
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’è¿½åŠ 
    human_message = HumanMessage(content=user_input)
    messages.append(human_message)
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’LLMã«é€ä¿¡
    response = llm.invoke(messages)
    answer = response.content
    
    return answer

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "selected_expert" not in st.session_state:
    st.session_state.selected_expert = "A"

# å°‚é–€å®¶ã®èª¬æ˜ã®å®šç¾©
EXPERT_DESCRIPTIONS = {
    "A": """* **ğŸ· æ·±å¤œã®ã‚«ãƒ«ãƒãƒ£ãƒ¼ãƒ»ã‚½ãƒ ãƒªã‚¨**
    * é™ã‹ãªå¤œã«ã€éš ã‚ŒãŸåä½œæ˜ ç”»ã‚„éŸ³æ¥½ã‚’èªã‚Šåˆã„ãŸã„æ™‚ã«ã€‚
    * ã‚ãªãŸã«ã´ã£ãŸã‚Šã®ãƒ‰ãƒªãƒ³ã‚¯ã‚‚ææ¡ˆã—ã¾ã™ã€‚""",
    "B": """* **âš”ï¸ ç•°ä¸–ç•Œè»¢ç”Ÿã®æ¡ˆå†…äºº**
    * é€€å±ˆãªæ—¥å¸¸ã‚’å¿˜ã‚Œã¦ã€ã‚¹ãƒªãƒ«ã‚ã‚‹å†’é™ºã«å‡ºã‹ã‘ãŸã„æ™‚ã«ã€‚
    * ã‚ãªãŸã®é¸æŠæ¬¡ç¬¬ã§ç‰©èªã®çµæœ«ãŒå¤‰ã‚ã‚Šã¾ã™ã€‚"""
}

# ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã®å®šç¾©
PLACEHOLDERS = {
    "A": "ä»Šå¤œã®æ°—åˆ†ã‚’æ•™ãˆã¦ãã ã•ã„",
    "B": "ã‚ãªãŸã®è¡Œå‹•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
}

# å…¥åŠ›ãƒ©ãƒ™ãƒ«ã®å®šç¾©
INPUT_LABELS = {
    "A": "ä»Šå¤œã®æ°—åˆ†ã‚’æ•™ãˆã¦ãã ã•ã„:",
    "B": "ã‚ãªãŸã®è¡Œå‹•ã‚’é¸æŠã—ã¦ãã ã•ã„:"
}

# ç”»é¢ã«å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã‚’è¡¨ç¤º
st.markdown("### ğŸšª ã‚ãªãŸã¯ä»Šæ—¥ã€èª°ã¨è©±ã‚’ã—ã¾ã™ã‹ï¼Ÿ")
st.markdown("""
ã“ã“ã¯ã€è¨€è‘‰ä¸€ã¤ã§ä¸–ç•ŒãŒå¤‰ã‚ã‚‹ä¸æ€è­°ãªãƒãƒ£ãƒƒãƒˆãƒ«ãƒ¼ãƒ ã§ã™ã€‚
ä»Šã®ã‚ãªãŸã®æ°—åˆ†ã«åˆã‚ã›ã¦ã€ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚
""")

# å°‚é–€å®¶ã®é¸æŠï¼ˆãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ï¼‰
expert_options = {
    "A": "æ·±å¤œã®ã‚«ãƒ«ãƒãƒ£ãƒ¼ãƒ»ã‚½ãƒ ãƒªã‚¨",
    "B": "ç•°ä¸–ç•Œè»¢ç”Ÿã®æ¡ˆå†…äºº"
}

selected_expert = st.radio(
    "ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ã‚’é¸æŠã—ã¦ãã ã•ã„:",
    options=list(expert_options.keys()),
    format_func=lambda x: expert_options[x],
    index=list(expert_options.keys()).index(st.session_state.selected_expert)
)

# å°‚é–€å®¶ãŒå¤‰æ›´ã•ã‚ŒãŸã‚‰å±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆ
if selected_expert != st.session_state.selected_expert:
    st.session_state.chat_history = []
    st.session_state.selected_expert = selected_expert
    st.rerun()

# é¸æŠã—ãŸå°‚é–€å®¶ã®èª¬æ˜ã‚’è¡¨ç¤º
st.markdown(EXPERT_DESCRIPTIONS[selected_expert])

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
if st.session_state.chat_history:
    st.subheader("ä¼šè©±å±¥æ­´")
    for message in st.session_state.chat_history:
        if isinstance(message, HumanMessage):
            with st.chat_message("user"):
                st.write(message.content)
        elif isinstance(message, AIMessage):
            with st.chat_message("assistant"):
                st.write(message.content)

# å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
placeholder_text = PLACEHOLDERS[selected_expert]
input_label = INPUT_LABELS[selected_expert]
user_input = st.text_input(input_label, placeholder=placeholder_text, key="user_input")

# é€ä¿¡ãƒœã‚¿ãƒ³
if st.button("é€ä¿¡"):
    if not user_input:
        st.warning("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    elif not api_key:
        st.error("OPENAI_API_KEYãŒç’°å¢ƒå¤‰æ•°ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    else:
        try:
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’LLMã«é€ä¿¡
            with st.spinner("LLMãŒå›ç­”ã‚’ç”Ÿæˆä¸­..."):
                answer = get_llm_response(user_input, selected_expert, st.session_state.chat_history)
            
            # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã«è¿½åŠ 
            human_message = HumanMessage(content=user_input)
            st.session_state.chat_history.append(human_message)
            st.session_state.chat_history.append(AIMessage(content=answer))
            
            # å…¥åŠ›æ¬„ã‚’ã‚¯ãƒªã‚¢
            if "user_input" in st.session_state:
                del st.session_state.user_input
            
            # ãƒšãƒ¼ã‚¸ã‚’ãƒªãƒ­ãƒ¼ãƒ‰ã—ã¦å±¥æ­´ã‚’æ›´æ–°
            st.rerun()
            
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

# å±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹ãƒœã‚¿ãƒ³
if st.button("ä¼šè©±å±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
    st.session_state.chat_history = []
    st.rerun()
